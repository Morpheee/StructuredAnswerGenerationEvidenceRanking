{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "# https://github.com/huggingface/transformers/blob/main/examples/research_projects/rag-end2end-retriever/finetune_rag.py\n",
    "\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from pytorch_lightning import loggers as pl_loggers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../../../data_pre_processed/fold-1/articles_train.csv\")\n",
    "corpus_train = pd.read_csv(\"../../../data_pre_processed/fold-1/corpus_train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(\"../../../data_pre_processed/fold-2/articles_train.csv\")\n",
    "corpus_val = pd.read_csv(\"../../../data_pre_processed/fold-2/corpus_train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_contexts = corpus_train[\"text\"].tolist()\n",
    "train_questions = df_train[\"query\"].tolist()\n",
    "train_answers = df_train[\"text_w/o_heading_first_sentence_by_section\"].tolist()\n",
    "\n",
    "val_contexts = corpus_val[\"text\"].tolist()\n",
    "val_questions = df_val[\"query\"].tolist()\n",
    "val_answers = df_val[\"text_w/o_heading_first_sentence_by_section\"].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['question_encoder.bert_model.encoder.layer.10.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.0.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.10.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.2.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.3.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.7.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.6.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.2.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.0.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'question_encoder.bert_model.embeddings.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.0.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.5.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.3.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.9.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.0.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.0.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.5.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.7.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.3.output.dense.weight', 'question_encoder.bert_model.encoder.layer.3.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.2.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.8.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.6.output.dense.bias', 'question_encoder.bert_model.encoder.layer.2.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.7.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.10.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.10.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.11.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.11.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.7.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.5.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.7.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.5.output.dense.bias', 'question_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.2.attention.self.value.bias', 'question_encoder.bert_model.embeddings.token_type_embeddings.weight', 'question_encoder.bert_model.encoder.layer.1.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.11.output.dense.bias', 'question_encoder.bert_model.encoder.layer.2.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.6.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.3.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.4.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.3.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.4.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.3.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.5.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.7.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.4.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.5.output.dense.weight', 'question_encoder.bert_model.encoder.layer.11.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.5.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.10.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.9.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.9.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.1.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.3.output.dense.bias', 'question_encoder.bert_model.encoder.layer.10.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.8.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.1.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.2.output.dense.bias', 'question_encoder.bert_model.embeddings.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.6.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.11.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.8.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.6.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.1.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.6.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.5.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.2.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.9.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.10.output.dense.bias', 'question_encoder.bert_model.encoder.layer.9.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.7.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.5.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.2.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.11.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.1.output.dense.bias', 'question_encoder.bert_model.encoder.layer.4.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.3.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.8.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.3.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.5.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.7.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.11.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.6.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.1.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.6.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.6.output.dense.weight', 'question_encoder.bert_model.encoder.layer.8.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.0.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.1.output.dense.weight', 'question_encoder.bert_model.encoder.layer.4.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.3.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.7.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.9.output.dense.weight', 'question_encoder.bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.1.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.2.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.6.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.4.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.0.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.8.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.4.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.9.output.dense.bias', 'question_encoder.bert_model.encoder.layer.9.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.6.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.10.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.2.output.dense.weight', 'question_encoder.bert_model.encoder.layer.4.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.2.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.5.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.9.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.11.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.8.output.dense.weight', 'question_encoder.bert_model.encoder.layer.4.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.9.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.0.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.1.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.1.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.5.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.10.attention.self.value.weight', 'question_encoder.bert_model.pooler.dense.weight', 'question_encoder.bert_model.encoder.layer.8.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.8.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.1.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.1.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.0.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.11.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.7.output.dense.weight', 'question_encoder.bert_model.encoder.layer.5.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.6.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.11.attention.output.dense.bias', 'question_encoder.bert_model.embeddings.position_embeddings.weight', 'question_encoder.bert_model.encoder.layer.1.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.0.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.8.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.4.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.10.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.11.output.dense.weight', 'question_encoder.bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'question_encoder.bert_model.embeddings.word_embeddings.weight', 'question_encoder.bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.10.attention.self.value.bias', 'question_encoder.bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.4.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.10.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.8.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.7.output.dense.bias', 'question_encoder.bert_model.encoder.layer.8.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.0.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.2.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.11.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.1.attention.output.dense.bias', 'question_encoder.bert_model.encoder.layer.10.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.9.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.4.attention.self.query.weight', 'question_encoder.bert_model.encoder.layer.7.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.9.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.8.attention.self.value.bias', 'question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.encoder.layer.8.output.dense.bias', 'question_encoder.bert_model.encoder.layer.10.output.dense.weight', 'question_encoder.bert_model.encoder.layer.6.attention.self.value.weight', 'question_encoder.bert_model.encoder.layer.5.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.9.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.3.attention.self.query.bias', 'question_encoder.bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.3.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.4.output.dense.weight', 'question_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.0.output.dense.weight', 'question_encoder.bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.3.attention.self.key.bias', 'question_encoder.bert_model.encoder.layer.9.attention.output.dense.weight', 'question_encoder.bert_model.encoder.layer.2.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.0.output.dense.bias', 'question_encoder.bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.0.intermediate.dense.weight', 'question_encoder.bert_model.encoder.layer.6.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.4.output.dense.bias', 'question_encoder.bert_model.encoder.layer.7.attention.self.key.weight', 'question_encoder.bert_model.encoder.layer.11.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'question_encoder.bert_model.encoder.layer.7.intermediate.dense.bias', 'question_encoder.bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'question_encoder.bert_model.encoder.layer.11.attention.self.key.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DPRContextEncoder were not initialized from the model checkpoint at facebook/dpr-question_encoder-single-nq-base and are newly initialized: ['bert_model.encoder.layer.5.output.dense.bias', 'bert_model.encoder.layer.8.output.dense.weight', 'bert_model.encoder.layer.0.output.LayerNorm.bias', 'bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.9.attention.output.dense.weight', 'bert_model.encoder.layer.2.attention.output.dense.bias', 'bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.8.attention.self.query.bias', 'bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.output.dense.bias', 'bert_model.embeddings.position_embeddings.weight', 'bert_model.encoder.layer.7.attention.self.value.weight', 'bert_model.encoder.layer.2.attention.self.key.bias', 'bert_model.encoder.layer.0.intermediate.dense.weight', 'bert_model.encoder.layer.5.attention.self.key.bias', 'bert_model.encoder.layer.7.attention.self.key.bias', 'bert_model.encoder.layer.6.attention.self.key.bias', 'bert_model.encoder.layer.1.output.LayerNorm.bias', 'bert_model.encoder.layer.11.attention.self.query.bias', 'bert_model.encoder.layer.3.attention.output.dense.weight', 'bert_model.encoder.layer.3.output.dense.bias', 'bert_model.encoder.layer.7.attention.self.value.bias', 'bert_model.encoder.layer.4.attention.self.key.weight', 'bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.11.output.LayerNorm.weight', 'bert_model.encoder.layer.9.intermediate.dense.bias', 'bert_model.encoder.layer.1.attention.self.key.weight', 'bert_model.embeddings.token_type_embeddings.weight', 'bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.7.attention.self.query.weight', 'bert_model.encoder.layer.10.attention.output.dense.bias', 'bert_model.encoder.layer.11.intermediate.dense.bias', 'bert_model.embeddings.word_embeddings.weight', 'bert_model.encoder.layer.8.intermediate.dense.bias', 'bert_model.encoder.layer.2.attention.self.value.weight', 'bert_model.encoder.layer.8.attention.self.key.bias', 'bert_model.encoder.layer.11.output.dense.weight', 'bert_model.encoder.layer.5.attention.self.query.weight', 'bert_model.encoder.layer.2.output.dense.bias', 'bert_model.encoder.layer.3.intermediate.dense.bias', 'bert_model.encoder.layer.3.attention.self.value.bias', 'bert_model.encoder.layer.7.output.dense.weight', 'bert_model.encoder.layer.2.output.LayerNorm.bias', 'bert_model.encoder.layer.6.intermediate.dense.weight', 'bert_model.encoder.layer.5.output.LayerNorm.weight', 'bert_model.encoder.layer.0.attention.self.query.weight', 'bert_model.encoder.layer.7.attention.self.query.bias', 'bert_model.encoder.layer.9.attention.self.key.weight', 'bert_model.encoder.layer.9.attention.self.value.bias', 'bert_model.encoder.layer.4.attention.output.dense.weight', 'bert_model.encoder.layer.6.output.LayerNorm.weight', 'bert_model.encoder.layer.1.attention.output.dense.weight', 'bert_model.encoder.layer.5.attention.self.value.bias', 'bert_model.encoder.layer.0.attention.self.value.bias', 'bert_model.encoder.layer.9.attention.output.dense.bias', 'bert_model.embeddings.LayerNorm.bias', 'bert_model.encoder.layer.6.attention.self.value.weight', 'bert_model.encoder.layer.10.attention.self.query.bias', 'bert_model.encoder.layer.6.attention.self.value.bias', 'bert_model.encoder.layer.9.output.LayerNorm.bias', 'bert_model.encoder.layer.1.output.LayerNorm.weight', 'bert_model.encoder.layer.2.attention.self.query.bias', 'bert_model.encoder.layer.7.attention.output.dense.weight', 'bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.2.attention.output.dense.weight', 'bert_model.encoder.layer.10.output.LayerNorm.bias', 'bert_model.encoder.layer.11.attention.self.query.weight', 'bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.2.output.dense.weight', 'bert_model.encoder.layer.1.attention.output.dense.bias', 'bert_model.encoder.layer.0.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.self.key.bias', 'bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.0.output.dense.weight', 'bert_model.encoder.layer.5.intermediate.dense.bias', 'bert_model.encoder.layer.10.intermediate.dense.bias', 'bert_model.encoder.layer.10.attention.self.key.weight', 'bert_model.encoder.layer.10.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.self.value.weight', 'bert_model.encoder.layer.1.output.dense.bias', 'bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.0.attention.self.query.bias', 'bert_model.encoder.layer.0.attention.self.key.weight', 'bert_model.encoder.layer.4.attention.self.query.weight', 'bert_model.encoder.layer.6.attention.output.dense.weight', 'bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.9.attention.self.query.weight', 'bert_model.encoder.layer.5.attention.self.key.weight', 'bert_model.encoder.layer.6.output.dense.weight', 'bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.0.attention.output.dense.weight', 'bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.6.output.LayerNorm.bias', 'bert_model.encoder.layer.2.attention.self.value.bias', 'bert_model.encoder.layer.11.intermediate.dense.weight', 'bert_model.encoder.layer.8.output.LayerNorm.bias', 'bert_model.encoder.layer.10.attention.self.value.bias', 'bert_model.encoder.layer.4.output.LayerNorm.bias', 'bert_model.encoder.layer.0.attention.output.dense.bias', 'bert_model.encoder.layer.10.attention.self.key.bias', 'bert_model.encoder.layer.10.output.dense.weight', 'bert_model.encoder.layer.4.attention.self.value.weight', 'bert_model.encoder.layer.7.intermediate.dense.bias', 'bert_model.encoder.layer.10.attention.output.dense.weight', 'bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.4.output.dense.weight', 'bert_model.encoder.layer.11.attention.self.key.weight', 'bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.5.intermediate.dense.weight', 'bert_model.encoder.layer.9.attention.self.query.bias', 'bert_model.encoder.layer.4.attention.self.query.bias', 'bert_model.encoder.layer.1.attention.self.query.weight', 'bert_model.encoder.layer.1.attention.self.query.bias', 'bert_model.encoder.layer.1.attention.self.value.bias', 'bert_model.encoder.layer.0.attention.self.value.weight', 'bert_model.encoder.layer.8.attention.self.value.bias', 'bert_model.encoder.layer.11.attention.output.dense.bias', 'bert_model.encoder.layer.6.output.dense.bias', 'bert_model.encoder.layer.1.intermediate.dense.bias', 'bert_model.encoder.layer.9.output.dense.bias', 'bert_model.encoder.layer.3.output.LayerNorm.bias', 'bert_model.encoder.layer.5.attention.output.dense.weight', 'bert_model.encoder.layer.6.attention.self.key.weight', 'bert_model.encoder.layer.8.attention.self.value.weight', 'bert_model.encoder.layer.8.attention.output.dense.weight', 'bert_model.encoder.layer.2.intermediate.dense.bias', 'bert_model.encoder.layer.3.intermediate.dense.weight', 'bert_model.encoder.layer.10.output.dense.bias', 'bert_model.encoder.layer.11.attention.self.value.bias', 'bert_model.encoder.layer.7.output.LayerNorm.bias', 'bert_model.embeddings.LayerNorm.weight', 'bert_model.encoder.layer.1.output.dense.weight', 'bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.5.attention.self.query.bias', 'bert_model.encoder.layer.8.attention.self.query.weight', 'bert_model.encoder.layer.9.attention.self.key.bias', 'bert_model.encoder.layer.2.output.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.self.query.bias', 'bert_model.encoder.layer.8.output.LayerNorm.weight', 'bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.3.output.dense.weight', 'bert_model.encoder.layer.9.output.LayerNorm.weight', 'bert_model.encoder.layer.0.output.dense.bias', 'bert_model.encoder.layer.10.attention.self.query.weight', 'bert_model.encoder.layer.11.output.LayerNorm.bias', 'bert_model.encoder.layer.3.attention.self.key.bias', 'bert_model.encoder.layer.4.attention.output.dense.bias', 'bert_model.encoder.layer.1.attention.self.key.bias', 'bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.3.output.LayerNorm.weight', 'bert_model.encoder.layer.4.output.LayerNorm.weight', 'bert_model.encoder.layer.4.intermediate.dense.weight', 'bert_model.encoder.layer.7.attention.output.dense.bias', 'bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.7.intermediate.dense.weight', 'bert_model.encoder.layer.5.attention.self.value.weight', 'bert_model.encoder.layer.8.attention.output.dense.bias', 'bert_model.encoder.layer.10.intermediate.dense.weight', 'bert_model.encoder.layer.3.attention.output.dense.bias', 'bert_model.encoder.layer.0.intermediate.dense.bias', 'bert_model.encoder.layer.5.output.LayerNorm.bias', 'bert_model.encoder.layer.5.attention.output.dense.bias', 'bert_model.encoder.layer.7.attention.self.key.weight', 'bert_model.encoder.layer.0.attention.self.key.bias', 'bert_model.encoder.layer.2.intermediate.dense.weight', 'bert_model.encoder.layer.7.output.LayerNorm.weight', 'bert_model.encoder.layer.8.intermediate.dense.weight', 'bert_model.encoder.layer.1.intermediate.dense.weight', 'bert_model.encoder.layer.3.attention.self.value.weight', 'bert_model.encoder.layer.4.attention.self.value.bias', 'bert_model.encoder.layer.5.output.dense.weight', 'bert_model.encoder.layer.6.attention.self.query.weight', 'bert_model.encoder.layer.11.attention.output.dense.weight', 'bert_model.encoder.layer.2.attention.self.query.weight', 'bert_model.encoder.layer.8.output.dense.bias', 'bert_model.encoder.layer.4.attention.self.key.bias', 'bert_model.encoder.layer.1.attention.self.value.weight', 'bert_model.encoder.layer.4.output.dense.bias', 'bert_model.encoder.layer.10.attention.self.value.weight', 'bert_model.encoder.layer.3.attention.self.key.weight', 'bert_model.encoder.layer.6.attention.self.query.bias', 'bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.7.output.dense.bias', 'bert_model.encoder.layer.9.output.dense.weight', 'bert_model.encoder.layer.2.attention.self.key.weight', 'bert_model.encoder.layer.9.attention.self.value.weight', 'bert_model.encoder.layer.6.intermediate.dense.bias', 'bert_model.encoder.layer.4.intermediate.dense.bias', 'bert_model.encoder.layer.9.intermediate.dense.weight', 'bert_model.encoder.layer.6.attention.output.dense.bias', 'bert_model.encoder.layer.8.attention.self.key.weight', 'bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.self.query.weight', 'bert_model.encoder.layer.11.attention.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "qst_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "DPRContextEncoder(\n  (ctx_encoder): DPREncoder(\n    (bert_model): BertModel(\n      (embeddings): BertEmbeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (token_type_embeddings): Embedding(2, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (encoder): BertEncoder(\n        (layer): ModuleList(\n          (0): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (1): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (2): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (3): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (4): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (5): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (6): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (7): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (8): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (9): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (10): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (11): BertLayer(\n            (attention): BertAttention(\n              (self): BertSelfAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (output): BertSelfOutput(\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (intermediate): BertIntermediate(\n              (dense): Linear(in_features=768, out_features=3072, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): BertOutput(\n              (dense): Linear(in_features=3072, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_model_name = \"facebook/dpr-question_encoder-single-nq-base\"\n",
    "passage_model_name = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    "\n",
    "query_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(query_model_name)\n",
    "passage_tokenizer = DPRContextEncoderTokenizer.from_pretrained(passage_model_name)\n",
    "query_model = DPRQuestionEncoder.from_pretrained(query_model_name)\n",
    "passage_model = DPRContextEncoder.from_pretrained(passage_model_name)\n",
    "\n",
    "query_model.train()\n",
    "passage_model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_query_encodings = query_tokenizer(train_questions, truncation=True, padding=True, return_tensors = 'pt')\n",
    "train_context_encodings = passage_tokenizer(train_contexts, truncation=True, padding=True, return_tensors = 'pt')\n",
    "\n",
    "val_query_encodings = query_tokenizer(val_questions, truncation=True, padding=True, return_tensors = 'pt')\n",
    "val_context_encodings = passage_tokenizer(val_contexts, truncation=True, padding=True, return_tensors = 'pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class DPR(nn.Module):\n",
    "  def __init__(self, query_model, passage_model, query_tokenizer, passage_tokenizer,\n",
    "              dense_size, freeze_params = 0.0, batch_size = 2, sample_size = 4):\n",
    "\n",
    "    '''\n",
    "    :query_model : The model that encodes queries to dense representation\n",
    "    :passage_model : The model that encodes passages to dense representation\n",
    "    :query_tokenizer : tokenizer for queries\n",
    "    :passage_tokenizer : tokenizer for passages\n",
    "    :passage_dict : dictionary of passages with their unique id\n",
    "    :questions : A list of tuples with question and their correct passage id\n",
    "    :dense_size : the dimension to which the DPR has to encode\n",
    "    :freeze_params : the percentage of the parameters to be frozen\n",
    "    :batch_size : the batch size for training\n",
    "    :sample_size: the sample size for negative sampling\n",
    "    '''\n",
    "    super(DPR, self).__init__()\n",
    "    self.query_model = query_model\n",
    "    self.query_tokenizer = query_tokenizer\n",
    "    self.passage_model = passage_model\n",
    "    self.passage_tokenizer = passage_tokenizer\n",
    "    self.freeze_params = freeze_params\n",
    "    self.sample_size = sample_size\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "    self.passage_to_dense = nn.Sequential(nn.Linear(768, dense_size * 2),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(dense_size * 2, dense_size),\n",
    "                                          nn.GELU())\n",
    "\n",
    "    self.query_to_dense = nn.Sequential(nn.Linear(768, dense_size * 2),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(dense_size * 2, dense_size),\n",
    "                                          nn.GELU())\n",
    "    self.log_softmax = nn.LogSoftmax(dim = 1)\n",
    "    self.freeze_layers()\n",
    "\n",
    "\n",
    "  # Freeze the first self.freeze_params % layers\n",
    "  def freeze_layers(self):\n",
    "    num_query_layers = sum(1 for _ in self.query_model.parameters())\n",
    "    num_passage_layers = sum(1 for _ in self.passage_model.parameters())\n",
    "\n",
    "    for parameters in list(self.query_model.parameters())[:int(self.freeze_params * num_query_layers)]:\n",
    "      parameters.requires_grad = False\n",
    "\n",
    "    for parameters in list(self.query_model.parameters())[int(self.freeze_params * num_query_layers):]:\n",
    "      parameters.requires_grad = True\n",
    "\n",
    "    for parameters in list(self.passage_model.parameters())[:int(self.freeze_params * num_passage_layers)]:\n",
    "      parameters.requires_grad = False\n",
    "\n",
    "    for parameters in list(self.passage_model.parameters())[int(self.freeze_params * num_passage_layers):]:\n",
    "      parameters.requires_grad = True\n",
    "\n",
    "  def get_passage_vectors(self, passage):\n",
    "    p_vector = self.passage_model(input_ids = passage.input_ids,\n",
    "                                  attention_mask = passage.attention_mask)\n",
    "    p_vector = self.query_to_dense(p_vector.pooler_output)\n",
    "    return p_vector\n",
    "\n",
    "  def get_query_vector(self, query):\n",
    "    q_vector = self.query_model(input_ids = query.input_ids,\n",
    "                                attention_mask = query.attention_mask)\n",
    "    q_vector = self.query_to_dense(q_vector.pooler_output)\n",
    "    return q_vector\n",
    "\n",
    "  def dot_product(self, q_vector, p_vector):\n",
    "    q_vector = q_vector.unsqueeze(1)\n",
    "    sim = torch.matmul(q_vector, torch.transpose(p_vector, -2, -1))\n",
    "    return sim\n",
    "\n",
    "  def forward(self, context_input_ids, context_attention_mask, query_input_ids, query_attention_mask):\n",
    "    dense_passage = self.passage_model(input_ids = context_input_ids, attention_mask = context_attention_mask)\n",
    "    dense_query = self.query_model(input_ids = query_input_ids, attention_mask = query_attention_mask)\n",
    "    dense_passage = dense_passage['pooler_output']\n",
    "    dense_query = dense_query['pooler_output']\n",
    "    dense_passage = self.passage_to_dense(dense_passage)\n",
    "    dense_query = self.query_to_dense(dense_query)\n",
    "    similarity_score = self.dot_product(dense_query, dense_passage)\n",
    "    similarity_score = similarity_score.squeeze(1)\n",
    "    logits = self.log_softmax(similarity_score)\n",
    "    return logits, dense_query, dense_passage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\") # torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "DPR(\n  (query_model): DPRQuestionEncoder(\n    (question_encoder): DPREncoder(\n      (bert_model): BertModel(\n        (embeddings): BertEmbeddings(\n          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n          (position_embeddings): Embedding(512, 768)\n          (token_type_embeddings): Embedding(2, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): BertEncoder(\n          (layer): ModuleList(\n            (0): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (1): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (2): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (3): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (4): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (5): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (6): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (7): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (8): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (9): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (10): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (11): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n  (passage_model): DPRContextEncoder(\n    (ctx_encoder): DPREncoder(\n      (bert_model): BertModel(\n        (embeddings): BertEmbeddings(\n          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n          (position_embeddings): Embedding(512, 768)\n          (token_type_embeddings): Embedding(2, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): BertEncoder(\n          (layer): ModuleList(\n            (0): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (1): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (2): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (3): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (4): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (5): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (6): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (7): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (8): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (9): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (10): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n            (11): BertLayer(\n              (attention): BertAttention(\n                (self): BertSelfAttention(\n                  (query): Linear(in_features=768, out_features=768, bias=True)\n                  (key): Linear(in_features=768, out_features=768, bias=True)\n                  (value): Linear(in_features=768, out_features=768, bias=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): BertSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): BertIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): BertOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n  (passage_to_dense): Sequential(\n    (0): Linear(in_features=768, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=64, bias=True)\n    (3): GELU()\n  )\n  (query_to_dense): Sequential(\n    (0): Linear(in_features=768, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=64, bias=True)\n    (3): GELU()\n  )\n  (log_softmax): LogSoftmax(dim=1)\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpr_model = DPR(query_model = query_model,\n",
    "                passage_model = passage_model,\n",
    "                query_tokenizer = query_tokenizer,\n",
    "                passage_tokenizer = passage_tokenizer,\n",
    "                dense_size = 64,\n",
    "                freeze_params = 0.3,\n",
    "                batch_size = 2,\n",
    "                sample_size = 8).to(device)\n",
    "\n",
    "dpr_model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model parameters :        217996672\n",
      "trainable parameters :    124251520\n"
     ]
    }
   ],
   "source": [
    "print(\"model parameters :\".ljust(25),sum(p.numel() for p in dpr_model.parameters()))\n",
    "print(\"trainable parameters :\".ljust(25),sum(p.numel() for p in dpr_model.parameters() if p.requires_grad == True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.AdamW(dpr_model.parameters(), lr = 5e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "neg_samples = 2\n",
    "num_questions = len(train_query_encodings.input_ids)\n",
    "num_contexts = len(train_context_encodings.input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_batch():\n",
    "  true = []\n",
    "  context_input_ids_tensor = []\n",
    "  context_attention_mask_tensor = []\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  true.append(1)\n",
    "\n",
    "  ## Selecting the query and its positive context\n",
    "  idx_query = random.randint(0, num_questions-1)\n",
    "  idx_context = random.randint(0, num_contexts-1)\n",
    "  context_input_ids = train_context_encodings.input_ids[idx_context]\n",
    "  context_attention_mask = train_context_encodings.attention_mask[idx_context]\n",
    "  query_input_ids = train_query_encodings.input_ids[idx_query]\n",
    "  query_attention_mask = train_query_encodings.attention_mask[idx_query]\n",
    "  context_input_ids_tensor.append(context_input_ids)\n",
    "  context_attention_mask_tensor.append(context_attention_mask)\n",
    "\n",
    "  ## Selecting the negative contexts which is hardcoded as 100 index from the selected positive context\n",
    "\n",
    "  for j in range(neg_samples):\n",
    "    true.append(0)\n",
    "    neg_idx_1 = idx_context + 100\n",
    "    neg_idx_2 = idx_context - 100\n",
    "    if neg_idx_1 < num_questions:\n",
    "      context_input_ids = train_context_encodings.input_ids[neg_idx_1]\n",
    "      context_attention_mask = train_context_encodings.attention_mask[neg_idx_1]\n",
    "      context_input_ids_tensor.append(context_input_ids)\n",
    "      context_attention_mask_tensor.append(context_attention_mask)\n",
    "\n",
    "    elif neg_idx_2 > 0:\n",
    "      context_input_ids = train_context_encodings.input_ids[neg_idx_2]\n",
    "      context_attention_mask = train_context_encodings.attention_mask[neg_idx_2]\n",
    "      context_input_ids_tensor.append(context_input_ids)\n",
    "      context_attention_mask_tensor.append(context_attention_mask)\n",
    "\n",
    "\n",
    "  context_input_ids_tensor = torch.stack(context_input_ids_tensor)\n",
    "  context_attention_mask_tensor = torch.stack(context_attention_mask_tensor)\n",
    "  query_input_ids = query_input_ids.unsqueeze(0)\n",
    "  query_attention_mask = query_attention_mask.unsqueeze(0)\n",
    "  return context_input_ids_tensor, context_attention_mask_tensor, query_input_ids, query_attention_mask, true"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred\n",
      "tensor([0, 2, 1])\n",
      "context\n",
      "['[CLS] cell signaling has been most extensively studied in the context of human diseases and signaling between cells ) of a single organism. however, cell signaling may also occur between the cells of two different organisms. in many mammals, early embryo cells exchange signals with cells of the uterus.. /.. in the human gastrointestinal tract, bacteria exchange signals with each other and with human epithelial and immune system cells. for the yeast saccharomyces cerevisiae during mating, some cells send a peptide signal ( mating factor pheromone on other yeast cells and induce them to prepare for mating. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] the onset of various environmental issues, especially climate change, has created potential conflicts between different human rights. human rights ultimately require a working ecosystem and healthy environment, but the granting of certain rights to individuals may damage these. such as the conflict between right to decide number of offspring and the common need for a healthy environment, as noted in the tragedy of the commons.. /.. in the area of environmental rights, the responsibilities of multinational corporations, so far relatively unaddressed by human rights legislation, is of paramount consideration. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]', '[CLS] the onset of various environmental issues, especially climate change, has created potential conflicts between different human rights. human rights ultimately require a working ecosystem and healthy environment, but the granting of certain rights to individuals may damage these. such as the conflict between right to decide number of offspring and the common need for a healthy environment, as noted in the tragedy of the commons.. /.. in the area of environmental rights, the responsibilities of multinational corporations, so far relatively unaddressed by human rights legislation, is of paramount consideration. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']\n",
      "query\n",
      "[CLS] dismissal ( employment ) [SEP] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "batch_loss = 0\n",
    "for i in range(1, 500):\n",
    "  context_input_ids_tensor, context_attention_mask_tensor,query_input_ids,query_attention_mask, true = get_batch()\n",
    "  pred, vec_q, vecs_p = dpr_model(context_input_ids_tensor.to(device),\n",
    "                   context_attention_mask_tensor.to(device),\n",
    "                   query_input_ids.to(device),\n",
    "                   query_attention_mask.to(device))\n",
    "  true = torch.tensor([0]).to(device)\n",
    "  print(\"pred\")\n",
    "  print(pred.argsort()[0])\n",
    "  print(\"context\")\n",
    "  print([passage_tokenizer.decode(p)  for p in context_input_ids_tensor])\n",
    "  print('query')\n",
    "  print(query_tokenizer.decode([q for q in query_input_ids[0]]))\n",
    "  break\n",
    "  # print(pred.size(), true.size())\n",
    "  loss = criterion(pred, true)\n",
    "  loss.backward()\n",
    "  batch_loss += loss.item()\n",
    "  optimizer.step()\n",
    "  if i%20 == 0:\n",
    "    print(f\"Batch : {int(i/20)}  Loss : {batch_loss/20}\")\n",
    "    batch_loss = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "vectors = torch.concat((vecs_p, vec_q)).detach().numpy()\n",
    "pca.fit_transform(vectors)\n",
    "vec_q_transformed = pca.transform(vec_q.detach().numpy())[0]\n",
    "vecs_p_transformed = pca.transform(vecs_p.detach().numpy())\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.ylim([-1,1])\n",
    "plt.xlim([-1,1])\n",
    "for vec in vecs_p_transformed :\n",
    "  plt.plot([0,vec[0]], [0,vec[1]], color=\"cyan\")\n",
    "plt.plot([0, vec_q_transformed[0]], [0, vec_q_transformed[1]], color=\"magenta\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}